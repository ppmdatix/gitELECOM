{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from loadingCGAN.cgan import Cgan\n",
    "from loadingCGAN.mlp import Mlp\n",
    "from evaluation.evaluation import evaluate\n",
    "from learning import learning\n",
    "import numpy as np\n",
    "from load_data.load_data import load_data\n",
    "from utils.config import epochs, number_of_gans, switches, latent_dim, nrows, dropout, leaky_relu, place, activation, noise\n",
    "from utils.config import examples, reload_images_p, show_past_p, smooth_zero, smooth_one, save_model, balanced_train_size\n",
    "from utils.config import spectral_normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape is (1000, 106)\n",
      "Test data shape is (1000, 106)\n",
      "\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "Train data shape is (968, 106)\n",
      "\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "x_train overview\n",
      "   0         1         2    3    4    5    6    7    8    9   ...   96   97   \\\n",
      "0 -1.0 -1.000000 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0   \n",
      "1 -1.0 -0.293850  0.069111 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0   \n",
      "2 -1.0 -0.267875  0.461147 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0   \n",
      "3 -1.0 -0.125970  0.067371 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0   \n",
      "4 -1.0 -0.248570  0.152452 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 ...  -1.0 -1.0   \n",
      "\n",
      "   98   99   100  101  102  103  104  105  \n",
      "0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "2 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "3 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "4 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  \n",
      "\n",
      "[5 rows x 106 columns]\n",
      "\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "y_train overview\n",
      "     0\n",
      "0  1.0\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  0.0\n",
      "\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# DATA\n",
    "x_train, x_train_cv, y_train, y_train_cv, x_balanced_train, y_balanced_train, x_test, y_test = load_data(place=place,\n",
    "                                                                                                         nrows=nrows,\n",
    "                                                                                                         cv_size=.1,\n",
    "                                                                                                         log_transform=True,\n",
    "                                                                                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.0\n"
     ]
    }
   ],
   "source": [
    "if balanced_train_size is not None:\n",
    "    x_balanced_train, y_balanced_train = x_balanced_train[:balanced_train_size], y_balanced_train[:balanced_train_size]\n",
    "\n",
    "data_dim = x_train.shape[1]\n",
    "print(y_train_cv.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "CHOSEN OPTIMIZER IS ADAM\n",
      "WARNING:tensorflow:From /Users/ppx/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\n",
      " \n",
      " Discriminator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 18)                1926      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2,297\n",
      "Trainable params: 2,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " \n",
      " Generator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 106)               6890      \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/Desktop/gitELECOM/cGANoDEbergerac/loadingCGAN/cgan.py:112: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=32, kernel_initializer=<keras.ini..., kernel_constraint=None)`\n",
      "  W_constraint=kernel_constraint))\n",
      "/Users/ppx/Desktop/gitELECOM/cGANoDEbergerac/loadingCGAN/cgan.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_initializer=<keras.ini..., kernel_constraint=None)`\n",
      "  W_constraint=kernel_constraint))\n",
      "/Users/ppx/Desktop/gitELECOM/cGANoDEbergerac/loadingCGAN/cgan.py:122: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(106, kernel_initializer=<keras.ini..., kernel_constraint=None)`\n",
      "  W_constraint=kernel_constraint))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHOSEN OPTIMIZER IS ADAM\n",
      "\n",
      " \n",
      " Discriminator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 18)                1926      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2,297\n",
      "Trainable params: 2,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " \n",
      " Generator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 106)               6890      \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CHOSEN OPTIMIZER IS ADAM\n",
      "\n",
      " \n",
      " Discriminator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 18)                1926      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2,297\n",
      "Trainable params: 2,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " \n",
      " Generator Architecture \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 12)                396       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 106)               6890      \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.44it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.16it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 30us/step\n",
      "  32/1000 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step\n",
      "1000/1000 [==============================] - 0s 314us/step\n",
      "1000/1000 [==============================] - 0s 28us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 357us/step\n",
      "1000/1000 [==============================] - 0s 27us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 332us/step\n",
      "Let's switch the GANs\n",
      "There are 1 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 41us/step\n",
      "1000/1000 [==============================] - 0s 40us/step\n",
      "1000/1000 [==============================] - 0s 430us/step\n",
      "1000/1000 [==============================] - 0s 27us/step\n",
      "1000/1000 [==============================] - 0s 34us/step\n",
      "1000/1000 [==============================] - 0s 374us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 31us/step\n",
      "1000/1000 [==============================] - 0s 360us/step\n",
      "Let's switch the GANs\n",
      "There are 1 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 28us/step\n",
      "1000/1000 [==============================] - 0s 28us/step\n",
      "1000/1000 [==============================] - 0s 339us/step\n",
      "1000/1000 [==============================] - 0s 35us/step\n",
      "1000/1000 [==============================] - 0s 40us/step\n",
      "1000/1000 [==============================] - 0s 373us/step\n",
      "1000/1000 [==============================] - 0s 45us/step\n",
      "1000/1000 [==============================] - 0s 35us/step\n",
      "1000/1000 [==============================] - 0s 324us/step\n",
      "Let's switch the GANs\n",
      "There are 1 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 38us/step\n",
      "1000/1000 [==============================] - 0s 48us/step\n",
      "1000/1000 [==============================] - 0s 353us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 358us/step\n",
      "1000/1000 [==============================] - 0s 27us/step\n",
      "1000/1000 [==============================] - 0s 25us/step\n",
      "1000/1000 [==============================] - 0s 345us/step\n",
      "Let's switch the GANs\n",
      "There are 1 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 30us/step\n",
      "1000/1000 [==============================] - 0s 357us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 30us/step\n",
      "1000/1000 [==============================] - 0s 351us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 29us/step\n",
      "1000/1000 [==============================] - 0s 449us/step\n",
      "Results of the deleted generator : \n",
      "{'confusion_matrix': array([[54,  2],\n",
      "       [16, 28]]), 'precision': 0.933, 'recall': 0.636, 'f1_score': 0.756, 'accuracy': 0.8200000000000001}\n",
      "\n",
      "\n",
      "\n",
      "best generator loss is 0.2340651807111156\n",
      "\n",
      "\n",
      "\n",
      "f1 score is 1.5498078994665827\n",
      "f1 score is 1.494523264169693\n",
      "f1 score is 1.4548801577772417\n",
      "{'confusion_matrix': array([[41, 15],\n",
      "       [ 2, 42]]), 'precision': 0.736, 'recall': 0.9540000000000001, 'f1_score': 0.8310000000000001, 'accuracy': 0.8300000000000001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confusion_matrix': array([[52,  4],\n",
      "       [18, 26]]), 'precision': 0.866, 'recall': 0.59, 'f1_score': 0.7020000000000001, 'accuracy': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.00it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  32/1000 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 43us/step\n",
      "1000/1000 [==============================] - 0s 46us/step\n",
      "1000/1000 [==============================] - 0s 42us/step\n",
      "1000/1000 [==============================] - 0s 36us/step\n",
      "1000/1000 [==============================] - 0s 36us/step\n",
      "1000/1000 [==============================] - 0s 38us/step\n",
      "Let's switch the GANs\n",
      "There are 2 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 30us/step\n",
      "1000/1000 [==============================] - 0s 41us/step\n",
      "1000/1000 [==============================] - 1s 502us/step\n",
      "1000/1000 [==============================] - 0s 30us/step\n",
      "1000/1000 [==============================] - 0s 31us/step\n",
      "1000/1000 [==============================] - 0s 433us/step\n",
      "Let's switch the GANs\n",
      "There are 2 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 32us/step\n",
      "1000/1000 [==============================] - 0s 34us/step\n",
      "1000/1000 [==============================] - 1s 541us/step\n",
      "1000/1000 [==============================] - 0s 36us/step\n",
      "1000/1000 [==============================] - 0s 61us/step\n",
      "1000/1000 [==============================] - 0s 457us/step\n",
      "Let's switch the GANs\n",
      "There are 2 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 49us/step\n",
      "1000/1000 [==============================] - 0s 41us/step\n",
      "1000/1000 [==============================] - 0s 491us/step\n",
      "1000/1000 [==============================] - 0s 38us/step\n",
      "1000/1000 [==============================] - 0s 36us/step\n",
      "1000/1000 [==============================] - 0s 498us/step\n",
      "Let's switch the GANs\n",
      "There are 0 fixed points\n",
      "GANs switched\n",
      "1000/1000 [==============================] - 0s 44us/step\n",
      "1000/1000 [==============================] - 0s 41us/step\n",
      "1000/1000 [==============================] - 0s 468us/step\n",
      "1000/1000 [==============================] - 0s 25us/step\n",
      "1000/1000 [==============================] - 0s 27us/step\n",
      "1000/1000 [==============================] - 0s 478us/step\n",
      "Results of the deleted generator : \n",
      "{'confusion_matrix': array([[44, 12],\n",
      "       [ 3, 41]]), 'precision': 0.773, 'recall': 0.931, 'f1_score': 0.845, 'accuracy': 0.85}\n",
      "\n",
      "\n",
      "\n",
      "best generator loss is 0.35194361230529525\n",
      "\n",
      "\n",
      "\n",
      "f1 score is 1.5459228299742653\n",
      "f1 score is 1.7986540418465933\n",
      "{'confusion_matrix': array([[52,  4],\n",
      "       [18, 26]]), 'precision': 0.866, 'recall': 0.59, 'f1_score': 0.7020000000000001, 'accuracy': 0.78}\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# CGAN #\n",
    "########\n",
    "cgans = [Cgan(data_dim=data_dim, latent_dim=latent_dim,\n",
    "              spectral_normalisation=spectral_normalisation,\n",
    "              weight_clipping=False, verbose=True,noise=noise,\n",
    "              activation=activation, dropout=dropout, leaky_relu=leaky_relu) for _ in range(number_of_gans)]\n",
    "\n",
    "\n",
    "cgans = learning(cgans=cgans, x=x_balanced_train, y=y_balanced_train, x_cv=x_train_cv,\n",
    "                 y_cv=y_train_cv, number_of_gans=number_of_gans,\n",
    "                 epochs=epochs, switches=switches, print_mode=False, mode_d_loss=True,\n",
    "                 reload_images_p=reload_images_p, show_past_p=show_past_p,\n",
    "                 smooth_zero=smooth_zero, smooth_one=smooth_one)\n",
    "\n",
    "\n",
    "cgan = cgans[0]\n",
    "if save_model:\n",
    "    cgan.save_model(location=\"save_models/models/\", model_name=\"test1\")\n",
    "# cgano = cgans[number_of_gans - 1]\n",
    "# cgano.load_model(location=\"save_models/models/\", model_name=\"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.335971  , 0.66174316, 0.67197335, 0.32725155, 0.32405102,\n",
       "       0.33826715, 0.67245388, 0.6722973 , 0.67265487, 0.67231953,\n",
       "       0.33830565, 0.67223495, 0.33062416, 0.33277214, 0.66919851,\n",
       "       0.6721074 , 0.32646179, 0.3539077 , 0.32491332, 0.32524198,\n",
       "       0.67285299, 0.67243028, 0.32573354, 0.65907425, 0.67297387,\n",
       "       0.34191298, 0.67245537, 0.32733548, 0.3230812 , 0.32334709,\n",
       "       0.35950083, 0.66524005, 0.32777369, 0.3415485 , 0.33076888,\n",
       "       0.33944428, 0.33089316, 0.66901267, 0.32434225, 0.67344332,\n",
       "       0.667732  , 0.67387998, 0.33417314, 0.65950787, 0.32321256,\n",
       "       0.66323984, 0.34573174, 0.32360768, 0.33189869, 0.66956818,\n",
       "       0.32420498, 0.33889931, 0.34793252, 0.32677412, 0.33079445,\n",
       "       0.33550525, 0.35914326, 0.66791683, 0.66461909, 0.33088183,\n",
       "       0.328022  , 0.33853376, 0.34380454, 0.32313341, 0.33860105,\n",
       "       0.32855117, 0.3458004 , 0.67175883, 0.34054196, 0.66891277,\n",
       "       0.32673717, 0.672041  , 0.34148061, 0.333915  , 0.67247254,\n",
       "       0.3294515 , 0.66464299, 0.32639188, 0.32371092, 0.33836156,\n",
       "       0.32779539, 0.33787465, 0.66704142, 0.35988533, 0.32430267,\n",
       "       0.67081308, 0.32314205, 0.6659075 , 0.33827603, 0.65913534,\n",
       "       0.32414311, 0.32558817, 0.33101916, 0.33869052, 0.6635161 ,\n",
       "       0.33469689, 0.65700299, 0.3315649 , 0.65947402, 0.67239267,\n",
       "       0.33005393, 0.3249256 , 0.34654295, 0.32366621, 0.34789264,\n",
       "       0.32535487, 0.32333761, 0.33096737, 0.32651764, 0.33467036,\n",
       "       0.32550102, 0.33467036, 0.33680898, 0.32959569, 0.32682127,\n",
       "       0.35509533, 0.33747029, 0.331137  , 0.32833445, 0.32428002,\n",
       "       0.33748484, 0.33726424, 0.6634112 , 0.3299216 , 0.67382693,\n",
       "       0.66201693, 0.33111256, 0.32820612, 0.3309077 , 0.33984303,\n",
       "       0.67236638, 0.34758216, 0.33239591, 0.32848328, 0.67240584,\n",
       "       0.66931576, 0.66099554, 0.32739663, 0.3417871 , 0.67243558,\n",
       "       0.32308733, 0.33774447, 0.34026617, 0.32430243, 0.32932329,\n",
       "       0.3270613 , 0.66857803, 0.32586396, 0.33163172, 0.66705406,\n",
       "       0.6722486 , 0.32606763, 0.67079079, 0.66626942, 0.67324132,\n",
       "       0.33070564, 0.33400488, 0.67148709, 0.36061668, 0.67170447,\n",
       "       0.32443166, 0.33065605, 0.33088493, 0.32914472, 0.67278463,\n",
       "       0.35424316, 0.66134769, 0.32855642, 0.33606553, 0.32611305,\n",
       "       0.67106879, 0.3310039 , 0.34216166, 0.34390974, 0.67225587,\n",
       "       0.67171681, 0.33843982, 0.34423244, 0.66330504, 0.65992361,\n",
       "       0.34077036, 0.33594227, 0.33573616, 0.32821774, 0.34662569,\n",
       "       0.66792512, 0.67221117, 0.67213351, 0.33508933, 0.32497847,\n",
       "       0.34910393, 0.32578981, 0.67253798, 0.66319489, 0.32609218,\n",
       "       0.33004516, 0.32831395, 0.32793355, 0.34438193, 0.32552058,\n",
       "       0.32323778, 0.6730938 , 0.32361096, 0.32934457, 0.3269608 ,\n",
       "       0.32995284, 0.67333037, 0.32626063, 0.32962513, 0.67189085,\n",
       "       0.34331709, 0.3551445 , 0.65985948, 0.32303959, 0.66859365,\n",
       "       0.67617232, 0.32390785, 0.32694507, 0.3254022 , 0.33445001,\n",
       "       0.32766759, 0.66657287, 0.33385944, 0.6667285 , 0.3604641 ,\n",
       "       0.32610559, 0.3252973 , 0.67197901, 0.32871908, 0.3319732 ,\n",
       "       0.33553326, 0.32567841, 0.34179038, 0.34558588, 0.33102316,\n",
       "       0.34623647, 0.66462135, 0.67219335, 0.66269076, 0.3246612 ,\n",
       "       0.32902408, 0.35310459, 0.67066795, 0.66784757, 0.66938466,\n",
       "       0.32411772, 0.67245054, 0.35919333, 0.67253733, 0.32344884,\n",
       "       0.35973585, 0.66199362, 0.32505381, 0.35426635, 0.66614759,\n",
       "       0.34259546, 0.32810605, 0.32420844, 0.34060264, 0.32692677,\n",
       "       0.67050886, 0.32976204, 0.32321721, 0.34115332, 0.3332516 ,\n",
       "       0.32493424, 0.32316846, 0.32847965, 0.35982424, 0.66304153,\n",
       "       0.32315791, 0.34970546, 0.33650386, 0.33074492, 0.33239943,\n",
       "       0.32541025, 0.67075014, 0.67259806, 0.33545887, 0.3233608 ,\n",
       "       0.32417142, 0.67016411, 0.33295918, 0.32524741, 0.6733104 ,\n",
       "       0.33352488, 0.66563302, 0.66590333, 0.32338953, 0.35392559,\n",
       "       0.34372282, 0.67204422, 0.66879821, 0.32671285, 0.33033532,\n",
       "       0.32538259, 0.3257615 , 0.35836101, 0.66102916, 0.67228734,\n",
       "       0.33766878, 0.33891237, 0.66804898, 0.3437382 , 0.32340193,\n",
       "       0.3599484 , 0.66491145, 0.32507592, 0.34657884, 0.327779  ,\n",
       "       0.66792297, 0.32461363, 0.33871114, 0.66787881, 0.32523894,\n",
       "       0.34176475, 0.36071992, 0.34238917, 0.33116716, 0.67247999,\n",
       "       0.33431971, 0.66946995, 0.67220706, 0.6736393 , 0.33477533,\n",
       "       0.67335993, 0.32335573, 0.32312709, 0.32830179, 0.33549345,\n",
       "       0.34443164, 0.3438707 , 0.33106029, 0.32662761, 0.67262101,\n",
       "       0.32401013, 0.33461416, 0.3247546 , 0.66929388, 0.33891129,\n",
       "       0.32595205, 0.67268819, 0.34284711, 0.32691658, 0.67377388,\n",
       "       0.34200436, 0.67236036, 0.33701533, 0.67320192, 0.34694171,\n",
       "       0.34380376, 0.32697409, 0.66912717, 0.32380879, 0.34477252,\n",
       "       0.32454091, 0.67162037, 0.32679003, 0.33775634, 0.65635067,\n",
       "       0.33104128, 0.3249737 , 0.66903424, 0.33563167, 0.32414794,\n",
       "       0.35852522, 0.32448137, 0.32495701, 0.66687143, 0.67258012,\n",
       "       0.32315171, 0.32817054, 0.32500821, 0.67313826, 0.3237406 ,\n",
       "       0.67352533, 0.34670252, 0.33757359, 0.34010321, 0.67245352,\n",
       "       0.33086014, 0.67349929, 0.33741021, 0.67171067, 0.6726228 ,\n",
       "       0.32874149, 0.66795522, 0.33187026, 0.32314122, 0.32894075,\n",
       "       0.32545018, 0.66098869, 0.66543907, 0.6715613 , 0.67288512,\n",
       "       0.672333  , 0.35621393, 0.67209595, 0.35172307, 0.34121203,\n",
       "       0.3241663 , 0.66679955, 0.337201  , 0.33106768, 0.35997868,\n",
       "       0.35955399, 0.32883275, 0.33153647, 0.67288679, 0.66448361,\n",
       "       0.32429719, 0.33888519, 0.32336855, 0.32729161, 0.66640347,\n",
       "       0.3313579 , 0.33515882, 0.6739437 , 0.67223442, 0.67255843,\n",
       "       0.3278451 , 0.34459883, 0.67260355, 0.33970928, 0.34651411,\n",
       "       0.32320762, 0.34185219, 0.33100462, 0.33525175, 0.34734344,\n",
       "       0.32897627, 0.34239924, 0.66765732, 0.32562667, 0.33081841,\n",
       "       0.32716572, 0.32511008, 0.33537513, 0.32517737, 0.32315373,\n",
       "       0.3372786 , 0.32868803, 0.67171019, 0.67008257, 0.32733715,\n",
       "       0.32763273, 0.34208941, 0.34583676, 0.67242301, 0.32307923,\n",
       "       0.33078998, 0.33135712, 0.67223048, 0.67147589, 0.66337281,\n",
       "       0.32344592, 0.33848083, 0.32432741, 0.66307402, 0.67256552,\n",
       "       0.65903902, 0.32823753, 0.66797   , 0.32487631, 0.32314295,\n",
       "       0.67230576, 0.32641059, 0.67062086, 0.33089995, 0.32746351,\n",
       "       0.67247802, 0.34181088, 0.33903587, 0.32731664, 0.66857535,\n",
       "       0.32919705, 0.32639897, 0.66668081, 0.36005706, 0.3286047 ,\n",
       "       0.33859748, 0.66889542, 0.66594923, 0.32325792, 0.33731848,\n",
       "       0.32522416, 0.32657945, 0.34459871, 0.66665167, 0.33636165,\n",
       "       0.67252409, 0.33547598, 0.33225214, 0.65220624, 0.32669586,\n",
       "       0.66640735, 0.33504516, 0.33355933, 0.32448715, 0.32325101,\n",
       "       0.32845199, 0.32765263, 0.67226112, 0.3232168 , 0.33245134,\n",
       "       0.6610325 , 0.33597249, 0.35921997, 0.33069742, 0.34793001,\n",
       "       0.34494418, 0.33470511, 0.32567734, 0.32319582, 0.3253063 ,\n",
       "       0.34957927, 0.67244869, 0.66967535, 0.32386994, 0.32561487,\n",
       "       0.67294425, 0.32806259, 0.66573566, 0.32670236, 0.3308661 ,\n",
       "       0.34024161, 0.67345124, 0.65952194, 0.34640086, 0.33738166,\n",
       "       0.65680516, 0.66954362, 0.66648221, 0.65963948, 0.6717335 ,\n",
       "       0.3323226 , 0.66537809, 0.33058435, 0.66390359, 0.32730854,\n",
       "       0.67335719, 0.6723029 , 0.33086801, 0.66206241, 0.32450587,\n",
       "       0.3254739 , 0.32785869, 0.6735363 , 0.33092999, 0.66566843,\n",
       "       0.33328611, 0.35984892, 0.3255564 , 0.67278337, 0.33934844,\n",
       "       0.33621103, 0.34792739, 0.67361081, 0.33864588, 0.665923  ,\n",
       "       0.33784974, 0.34526783, 0.32732654, 0.32644606, 0.67247522,\n",
       "       0.6720863 , 0.32534635, 0.34161425, 0.67383468, 0.32774961,\n",
       "       0.35286248, 0.66781312, 0.66767621, 0.66524959, 0.32314503,\n",
       "       0.35496843, 0.33283657, 0.67178637, 0.32768875, 0.33044893,\n",
       "       0.32706344, 0.33671784, 0.3434034 , 0.33102059, 0.33881521,\n",
       "       0.33203584, 0.35943043, 0.32820964, 0.32321477, 0.6735965 ,\n",
       "       0.32479256, 0.35119069, 0.67312932, 0.34139204, 0.32935739,\n",
       "       0.66928673, 0.66196901, 0.67352372, 0.33064103, 0.67218137,\n",
       "       0.6724956 , 0.32823014, 0.6720804 , 0.35363716, 0.32341397,\n",
       "       0.35418886, 0.67167407, 0.32670397, 0.32336652, 0.34558237,\n",
       "       0.32539439, 0.34648186, 0.32764018, 0.32949984, 0.32762462,\n",
       "       0.6689651 , 0.3463304 , 0.32695842, 0.33506078, 0.32480299,\n",
       "       0.33454609, 0.34759563, 0.3443951 , 0.32700741, 0.67234194,\n",
       "       0.67202812, 0.67224985, 0.67248416, 0.32368618, 0.34423536,\n",
       "       0.65917808, 0.34869933, 0.65996659, 0.32724458, 0.66333175,\n",
       "       0.33116186, 0.3260656 , 0.32792652, 0.66686523, 0.32443482,\n",
       "       0.67073858, 0.32676101, 0.32335079, 0.33884364, 0.65941727,\n",
       "       0.66685724, 0.66536498, 0.67029285, 0.67203742, 0.32417864,\n",
       "       0.66407657, 0.32804632, 0.35892004, 0.33063722, 0.33223677,\n",
       "       0.32394814, 0.32406467, 0.32698649, 0.33058697, 0.66916066,\n",
       "       0.33531475, 0.34522957, 0.66335762, 0.33226937, 0.32448488,\n",
       "       0.67205596, 0.3456555 , 0.33877671, 0.33905351, 0.33378744,\n",
       "       0.32315308, 0.67222476, 0.33718812, 0.34662896, 0.33188015,\n",
       "       0.32483661, 0.33603877, 0.32745326, 0.6644395 , 0.67192394,\n",
       "       0.34160805, 0.33077979, 0.3247295 , 0.32523662, 0.65897369,\n",
       "       0.33070129, 0.34202397, 0.66464537, 0.67212707, 0.34580773,\n",
       "       0.65654981, 0.32398593, 0.34920305, 0.67274368, 0.35104114,\n",
       "       0.34315777, 0.66634792, 0.33426142, 0.33027595, 0.32764184,\n",
       "       0.32482725, 0.33063352, 0.6591773 , 0.67130357, 0.3296243 ,\n",
       "       0.34575486, 0.33935624, 0.3413918 , 0.6725052 , 0.34248012,\n",
       "       0.33763915, 0.3304581 , 0.67229164, 0.67243075, 0.32365251,\n",
       "       0.67190874, 0.33286536, 0.33233732, 0.66668582, 0.65056825,\n",
       "       0.32830966, 0.33172613, 0.3305974 , 0.3273012 , 0.67215657,\n",
       "       0.66332471, 0.3230958 , 0.3308019 , 0.32526803, 0.32530236,\n",
       "       0.33380711, 0.32851923, 0.34067076, 0.33799767, 0.32617968,\n",
       "       0.32946557, 0.326451  , 0.66948104, 0.66791362, 0.33448154,\n",
       "       0.34234583, 0.67227829, 0.6706838 , 0.32770777, 0.66794783,\n",
       "       0.32693899, 0.32687068, 0.32908481, 0.34290111, 0.3254956 ,\n",
       "       0.67194998, 0.66930985, 0.33836132, 0.6715349 , 0.66780698,\n",
       "       0.32577002, 0.34129715, 0.33962154, 0.3463794 , 0.3595314 ,\n",
       "       0.66523117, 0.66881585, 0.32901317, 0.33895439, 0.3285045 ,\n",
       "       0.66691202, 0.34588355, 0.32663357, 0.33190811, 0.673491  ,\n",
       "       0.67326021, 0.66467851, 0.32497048, 0.32481802, 0.65900743,\n",
       "       0.67228478, 0.35480237, 0.33131069, 0.33822227, 0.33995759,\n",
       "       0.67218268, 0.35890907, 0.32567692, 0.32882792, 0.33649921,\n",
       "       0.35467827, 0.33086509, 0.34199238, 0.66842353, 0.3237288 ,\n",
       "       0.66917413, 0.32323045, 0.66992807, 0.6686269 , 0.6667726 ,\n",
       "       0.67230237, 0.66197878, 0.32476425, 0.67228353, 0.32785493,\n",
       "       0.32523912, 0.33604378, 0.33161134, 0.32978076, 0.3349337 ,\n",
       "       0.3308081 , 0.33830434, 0.34434998, 0.65978259, 0.32661116,\n",
       "       0.67246962, 0.3322522 , 0.67356908, 0.32337546, 0.33487248,\n",
       "       0.66761893, 0.32724279, 0.33585376, 0.32612944, 0.67179024,\n",
       "       0.32832432, 0.32333827, 0.32947993, 0.34534651, 0.6692276 ,\n",
       "       0.33042419, 0.67217219, 0.3271842 , 0.3261987 , 0.35900706,\n",
       "       0.32777685, 0.32445246, 0.3404218 , 0.32466245, 0.67257047,\n",
       "       0.33333474, 0.33828294, 0.32964545, 0.67180079, 0.33181703,\n",
       "       0.3470518 , 0.34748209, 0.33896661, 0.32605231, 0.6733638 ,\n",
       "       0.3233273 , 0.66673243, 0.67247903, 0.32339543, 0.66713864,\n",
       "       0.32798016, 0.3352738 , 0.66987294, 0.67341912, 0.32640529,\n",
       "       0.65988231, 0.67321342, 0.66240865, 0.342471  , 0.34706014,\n",
       "       0.33749241, 0.32361656, 0.34004319, 0.67185634, 0.67294818,\n",
       "       0.33577162, 0.33144742, 0.32753575, 0.34040278, 0.32493627,\n",
       "       0.67327732, 0.67268485, 0.32581371, 0.6711098 , 0.35921264,\n",
       "       0.673823  , 0.66643625, 0.672328  , 0.67345226, 0.32407767,\n",
       "       0.3235184 , 0.6718353 , 0.67370194, 0.33773792, 0.3393656 ,\n",
       "       0.32378316, 0.33442104, 0.34549892, 0.3260994 , 0.33396918,\n",
       "       0.32961416, 0.35956657, 0.33769155, 0.66630149, 0.6725204 ,\n",
       "       0.32923794, 0.34163982, 0.35861349, 0.34513551, 0.66791588,\n",
       "       0.34347987, 0.33205193, 0.33878005, 0.66032696, 0.34076697,\n",
       "       0.66552299, 0.32299119, 0.67261976, 0.32652372, 0.34091842,\n",
       "       0.34168088, 0.67313921, 0.66666234, 0.6721679 , 0.3590399 ,\n",
       "       0.66324556, 0.66899085, 0.67112064, 0.32357597, 0.33745885,\n",
       "       0.35944653, 0.32535607, 0.32354212, 0.6676119 , 0.32332939,\n",
       "       0.66238964, 0.33957219, 0.67242515, 0.66905391, 0.67254436,\n",
       "       0.33765435, 0.672481  , 0.32529753, 0.34495366, 0.34585685,\n",
       "       0.35453129, 0.32734263, 0.33068156, 0.3246572 , 0.32354015,\n",
       "       0.34421206, 0.66806239, 0.3304463 , 0.33229232, 0.32338262,\n",
       "       0.32560647, 0.66764402, 0.34044766, 0.33896858, 0.67373258,\n",
       "       0.33010364, 0.66295153, 0.33118784, 0.32378876, 0.33441919,\n",
       "       0.32696593, 0.34465575, 0.3326298 , 0.337457  , 0.67151582,\n",
       "       0.33457315, 0.33075082, 0.32901847, 0.66610223, 0.32708681,\n",
       "       0.33996201, 0.67302656, 0.67255831, 0.32937151, 0.33106387,\n",
       "       0.32886672, 0.33226287, 0.33060431, 0.34168905, 0.32719868,\n",
       "       0.34189624, 0.34170151, 0.66117436, 0.32892454, 0.32451838,\n",
       "       0.34886396, 0.33314216, 0.32677466, 0.32496023, 0.67207456,\n",
       "       0.32617462, 0.66600287, 0.33307314, 0.35961217, 0.6723749 ,\n",
       "       0.32701695, 0.67032671, 0.35211354, 0.66332084, 0.67638898,\n",
       "       0.34301609, 0.32588625, 0.67238253, 0.67279196, 0.32859945])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgan.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cgan.plot_learning()\n",
    "\n",
    "result_cgan = evaluate(y_true=y_test, y_pred=cgan.predict(x=x_test))\n",
    "print(\"\\n\"*4 +\"CGAN result\")\n",
    "print(result_cgan)\n",
    "\n",
    "\n",
    "#################\n",
    "# Classical MLP #\n",
    "#################\n",
    "mlp = Mlp(data_dim=data_dim, verbose=False)\n",
    "d_loss_classical = mlp.train(x_train=x_balanced_train,\n",
    "                             y_train=y_balanced_train,\n",
    "                             epochs=epochs*(switches+1))\n",
    "\n",
    "result_mlp = evaluate(y_true=y_test, y_pred=mlp.predict(x=x_test))\n",
    "\n",
    "print(\"\\n\"*2 + \"MLP result\")\n",
    "print(result_mlp)\n",
    "\n",
    "\n",
    "\n",
    "generated_one = cgan.generate(number=examples, labels=np.ones(examples))\n",
    "generated_zero = cgan.generate(number=examples, labels=np.zeros(examples))\n",
    "mlp_one = int(sum(mlp.predict(generated_one)))\n",
    "mlp_zero = int(sum(mlp.predict(generated_zero)))\n",
    "print(\"\\n\"*2 + \"MLP fooled by attacker attacking ?\")\n",
    "print(\"MLP predicts \" + str(mlp_one) + \" 1label on \" + str(examples) + \" examples\")\n",
    "print(\"\\n\"*2 + \"MLP fooled by attacker not attacking ?\")\n",
    "print(\"MLP predicts \" + str(mlp_zero) + \" 1label on \" + str(examples) + \" examples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
